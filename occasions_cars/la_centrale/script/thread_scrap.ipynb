{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lien du site : \n",
    "https://www.lacentrale.fr/auto-occasion-annonce-69113195868.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrappe la centrale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.service import Service\n",
    "from selenium.webdriver.common.service import Service\n",
    "from fake_useragent import UserAgent\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import random\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrappe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_aleatoire(driver):\n",
    "    actions_possibles = [\"scroll_full\", \"scroll_half\", \"move_to_element\"]\n",
    "    action_choisie = random.choice(actions_possibles)\n",
    "\n",
    "    # Enregistrer la position actuelle de la page\n",
    "    current_scroll_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "\n",
    "    if action_choisie == \"scroll_full\":\n",
    "        # Action aléatoire : Faites défiler la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    elif action_choisie == \"scroll_half\":\n",
    "        # Action aléatoire : Faites défiler la moitié de la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight / 2);\")\n",
    "    elif action_choisie == \"move_to_element\":\n",
    "        # Action aléatoire : Bougez la souris vers un élément aléatoire (par exemple, div de class PriceInformation_classifiedPrice__b-Jae)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element_to_move = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'PriceInformation_classifiedPrice__b-Jae')))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", element_to_move)\n",
    "\n",
    "    # Revenir à la position enregistrée\n",
    "    driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_element_with_retry(driver, by, value, max_retries=3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            element = driver.find_element(by, value)\n",
    "            return element\n",
    "        except NoSuchElementException:\n",
    "            retries += 1\n",
    "            time.sleep(2)  # Add a small delay before retrying\n",
    "    raise NoSuchElementException(f\"Element not found after {max_retries} retries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST  POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "def initialize_driver():\n",
    "    ua = UserAgent()\n",
    "    user_agent = ua.random\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    return webdriver.Firefox(options=options)\n",
    "base_url = \"https://www.lacentrale.fr/listing?makesModelsCommercialNames=&options=&page=\"\n",
    "xpath_expression = \"//a[contains(@class, 'Vehiculecard_Vehiculecard_vehiculeCard Vehiculecard_Vehiculecard_withBorder Containers_Containers_containers Containers_Containers_border Containers_Containers_borderRadius Containers_Containers_darkShadowWide')]\"\n",
    "data_final = []\n",
    "def scrape_page(base_url, start_page, step, driver, links):\n",
    "    current_page = start_page\n",
    "   \n",
    "   \n",
    "    \n",
    "    # Boucle pour parcourir les pages\n",
    "    while current_page < start_page + step:\n",
    "        # Construire l'URL de la page actuelle\n",
    "\n",
    "\n",
    "        url = base_url + str(current_page)\n",
    "        time.sleep(random.uniform(2, 6))\n",
    "\n",
    "        # Charger la page web\n",
    "        try:\n",
    "            driver.set_page_load_timeout(120)\n",
    "            driver.get(url)\n",
    "        except TimeoutException:\n",
    "            print(f\"TimeoutException: Unable to load {link}\")\n",
    "        try:\n",
    "            # Insérer ici le code pour extraire les liens ou effectuer d'autres opérations sur la page\n",
    "            all_links = driver.find_elements(By.XPATH, xpath_expression)\n",
    "            links = []\n",
    "            # Ajouter les liens à la liste\n",
    "            links.extend(link.get_attribute(\"href\") for link in all_links)\n",
    "            print(links)\n",
    "            # Parcourir chaque lien pour effectuer des opérations\n",
    "            for link in links:\n",
    "                try:\n",
    "                    # Afficher le lien trouvé\n",
    "                    print(\"Lien trouvé :\", link)\n",
    "                    data = []\n",
    "                    # Accéder à la page du lien\n",
    "                    driver.get(link)\n",
    "                    time.sleep(random.uniform(2, 5))\n",
    "\n",
    "                    # Insérer ici le code pour effectuer des opérations sur la page du lien\n",
    "\n",
    "                    try:\n",
    "                        time.sleep(random.uniform(2, 5))\n",
    "                        nom_xpath = \"//div[contains(@class, 'Text_Text_text SummaryInformation_title__5CYhW Text_Text_headline3')]\"\n",
    "\n",
    "                        nom = driver.find_element(By.XPATH, nom_xpath).text\n",
    "                        print(\"Nom du véhicule:\", nom)\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "                        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        nom = \" \"\n",
    "                        print(\"aucun nom trouvé\")\n",
    "                    data.append(nom)\n",
    "                    try:\n",
    "                        time.sleep(random.uniform(2, 5))\n",
    "                        carac_xpath = \"//div[contains(@class, 'Text_Text_text SummaryInformation_subtitle__M7MAb Text_Text_body2')]\"\n",
    "                        carac = driver.find_element(By.XPATH, carac_xpath).text\n",
    "                        #print(\"Carac:\", carac)\n",
    "\n",
    "                        # Diviser le texte en éléments\n",
    "                        elements = carac.split()\n",
    "                        action_aleatoire(driver)\n",
    "                        # Variables pour stocker les informations\n",
    "                        cylindree_moteur = \"\"\n",
    "                        type_moteur = \"\"\n",
    "                        puissance = \"\"\n",
    "                        finition = \"\"\n",
    "\n",
    "                        # Utiliser un indicateur pour savoir quel type d'information on traite actuellement\n",
    "                        current_type = None\n",
    "\n",
    "                        # Parcourir les éléments et attribuer aux variables appropriées\n",
    "                        for element in elements:\n",
    "                            # Vérifier s'il s'agit de la cylindrée du moteur (exprimée en centimètres cubes)\n",
    "                            if element.replace(\".\", \"\").isdigit() and not cylindree_moteur:\n",
    "                                cylindree_moteur = element\n",
    "                            # Vérifier s'il s'agit du type de moteur (contient des lettres)\n",
    "                            elif any(char.isalpha() for char in element) and not type_moteur:\n",
    "                                type_moteur = element\n",
    "                            # Vérifier s'il s'agit de la puissance (contient des chiffres)\n",
    "                            elif element.isdigit() and not puissance:\n",
    "                                puissance = element\n",
    "                            # Si ce n'est ni la cylindrée, ni le type, ni la puissance, c'est probablement la finition\n",
    "                            elif not finition:\n",
    "                                finition += element + \" \"\n",
    "\n",
    "                        cylindree_moteur = cylindree_moteur.strip()\n",
    "                        type_moteur = type_moteur.strip()\n",
    "                        puissance = puissance.strip()\n",
    "                        finition = finition.strip()\n",
    "                        # Afficher les résultats\n",
    "                        #print(\"Cylindrée du moteur:\", cylindree_moteur.strip())\n",
    "                        #print(\"Type de moteur:\", type_moteur.strip())\n",
    "                        #print(\"Puissance:\", puissance.strip())\n",
    "                        #print(\"Finition:\", finition.strip())\n",
    "                        data.append((cylindree_moteur,type_moteur,puissance,finition))\n",
    "                    except NoSuchElementException:\n",
    "                        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        carac = \" \"\n",
    "                        print(\"Carac non trouvé\")\n",
    "                    try:\n",
    "                        prix_xpath = \"//span[contains(@class, 'PriceInformation_classifiedPrice__b-Jae')]\"\n",
    "\n",
    "                        prix = driver.find_element(By.XPATH, prix_xpath).text\n",
    "                       # print(\"prix:\", prix)\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "                    except NoSuchElementException:\n",
    "                        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        prix = \" \"\n",
    "                        print(\"aucun nom trouvé\")\n",
    "                    data.append(prix)\n",
    "                    try:\n",
    "                        duree_publi_xpath = \"//div[contains(@class, 'Text_Text_text Text_Text_body2')]\"\n",
    "\n",
    "                        duree_publi = driver.find_element(By.XPATH, duree_publi_xpath).text\n",
    "                       # print(\"publié depuis:\",  duree_publi)\n",
    "                        time.sleep(random.uniform(2, 5))\n",
    "                    except NoSuchElementException:\n",
    "                        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        durée_publi = \" \"\n",
    "                        print(\"no durée publi renseigné\")\n",
    "                    data.append(duree_publi)\n",
    "                    try:\n",
    "                        volume_coffre_xpath = \"//div[contains(@class, 'Gauge_Gauge_gaugeWrapper')]//button[contains(@class, 'Gauge_Gauge_value Button_Button_button Button_Button_shaded Button_Button_small Button_Button_square')]//span[contains(@class, 'Text_Text_text Text_Text_label2')]\"\n",
    "                        volume_coffre_element = WebDriverWait(driver, 15).until(\n",
    "                                EC.presence_of_element_located((By.XPATH, volume_coffre_xpath))\n",
    "                        )\n",
    "\n",
    "                        volume_coffre = volume_coffre_element.get_attribute('textContent')\n",
    "                        # print(\"volume_coffre\", volume_coffre)\n",
    "                        time.sleep(random.uniform(2, 3))\n",
    "                    except NoSuchElementException:\n",
    "                        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        volume_coffre = \" \"\n",
    "                        print(\"no volume_coffrerenseigné\")\n",
    "                    except TimeoutException:\n",
    "                        # Gérer la TimeoutException ici\n",
    "                        print(\"Élément non trouvé après 15 secondes. Continuer avec le reste du code.\")\n",
    "                        volume_coffre = \" \"\n",
    "                    data.append(volume_coffre)\n",
    "                    try:\n",
    "                        spans_xpath = \"//span[contains(@class, 'Text_Text_text Icon-button_IconButton_label Text_Text_label2')]\"\n",
    "                        action_aleatoire(driver)\n",
    "                        spans = driver.find_elements(By.XPATH, spans_xpath)\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "        # Nombre de spans\n",
    "                        num_spans = len(spans)\n",
    "                        point_forts_values = []\n",
    "        # Créer des variables dynamiquement\n",
    "                        for index, span in enumerate(spans, start=1):\n",
    "            # Utilisation de JavaScript pour extraire le texte\n",
    "                            span_text = driver.execute_script(\"return arguments[0].textContent;\", span)\n",
    "                            variable_name = f\"point_fort{index}\"\n",
    "                            locals()[variable_name] = span_text.strip()\n",
    "                             #print(f\"{variable_name}:\", locals()[variable_name])\n",
    "                            point_forts_values.append(locals()[variable_name])\n",
    "\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "        # Si la div n'est pas trouvée sur la page du lien, afficher un message\n",
    "                        for index in range(1, num_spans + 1):\n",
    "                            variable_name = f\"point_fort{index}\"\n",
    "                            locals()[variable_name] = \" \"\n",
    "                            print(f\"{variable_name}: not found\")\n",
    "                            point_forts_values.append(locals()[variable_name])\n",
    "\n",
    "                        # Ajouter le tuple de valeurs des points forts à la liste data\n",
    "                    data.append(tuple(point_forts_values))\n",
    "                    h3_values = []\n",
    "                    try:\n",
    "                        h3_xpath = \"//h3[contains(@class, 'Text_Text_text Text_Text_subtitle1')]\"\n",
    "\n",
    "                        h3_elements = driver.find_elements(By.XPATH, h3_xpath)\n",
    "                        time.sleep(random.uniform(2, 3))\n",
    "\n",
    "                        for h3_element in h3_elements:\n",
    "                            try:\n",
    "                                ul_element = h3_element.find_element(By.XPATH, \"following-sibling::ul\")\n",
    "\n",
    "                                li_elements = ul_element.find_elements(By.XPATH, \"li\")\n",
    "                                li_values = []\n",
    "                                time.sleep(random.uniform(2, 3))\n",
    "                                for index, li_element in enumerate(li_elements, start=0):\n",
    "                                    \n",
    "                                    try:\n",
    "                                        # Essayer de trouver le texte du span directement\n",
    "                                        first_span_xpath = \".//span[contains(@class, 'Text_Text_text Text_Text_subtitle2')]\"\n",
    "                                        first_span_element = find_element_with_retry(li_element, By.XPATH, first_span_xpath)\n",
    "                                        variable_name = first_span_element.get_attribute('textContent')\n",
    "\n",
    "                                        span_xpath = \".//span[@class='Item_content__Xyd3d']\"\n",
    "                                        span_element = find_element_with_retry(li_element, By.XPATH, span_xpath)\n",
    "                                        variable_value = span_element.get_attribute('textContent')\n",
    "\n",
    "                                    except NoSuchElementException:\n",
    "                                        # Si le premier essai échoue, essayer de trouver le texte du span à l'intérieur\n",
    "                                        span_xpath = \".//span[@class='Item_content__Xyd3d']//span\"\n",
    "                                        span_element = find_element_with_retry(li_element, By.XPATH, span_xpath)\n",
    "                                        variable_value = span_element.get_attribute('textContent')\n",
    "                                    li_values.append((variable_name, variable_value))\n",
    "                                    # Maintenant, vous avez la valeur du texte du span, que ce soit directement ou à l'intérieur\n",
    "                                    #print(f\"Nom de la variable : {variable_name}, Valeur de la variable : {variable_value}\")\n",
    "                                h3_values.append(tuple(li_values))\n",
    "\n",
    "                            except NoSuchElementException:\n",
    "                                pass\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "                        print(\"H3 non trouvé\")\n",
    "                    data.append(tuple(h3_values))\n",
    "                    ########################EN COURS######################  \n",
    "                    button_class_name = \"Hyperlink_Hyperlink_hyperlink Hyperlink_Hyperlink_primary Hyperlink_Hyperlink_underline\"\n",
    "\n",
    "                    try:\n",
    "                        # Find the button using its class name\n",
    "                        button = driver.find_element(By.CLASS_NAME, button_class_name)\n",
    "\n",
    "                        # Click the button\n",
    "                        button.click()\n",
    "\n",
    "                        print(\"Button clicked successfully\")\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "                        print(f\"Button with class name '{button_class_name}' not found\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "\n",
    "                    ####Scrappe equipement####\n",
    "                    xpath_button_options = \"//div[contains(@class, 'EquipmentOptionsInformation_linkMoreEquipments__rd-QS')]//button[contains(@class, 'Hyperlink_Hyperlink_hyperlink Hyperlink_Hyperlink_primary Hyperlink_Hyperlink_underline')]\"\n",
    "                    try:\n",
    "                        # Attendre que le bouton soit cliquable\n",
    "                        button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_button_options)))\n",
    "\n",
    "                        # Utiliser ActionChains pour survoler et cliquer sur le bouton\n",
    "                        action = ActionChains(driver)\n",
    "                        action.move_to_element(button).click().perform()\n",
    "\n",
    "                        print(\"Button clicked successfully\")\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "                        print(f\"Button with XPath '{xpath_button_options}' not found\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "\n",
    "                    ####Scrappe equipement####\n",
    "                    # Dictionnaire pour stocker les résultats\n",
    "                    results = {}\n",
    "\n",
    "\n",
    "\n",
    "                    # XPath pour sélectionner les uls\n",
    "                    ul_xpaths = \"//ul[contains(@class, 'EquipmentOptionsInformation_column__rQp-a')]\"\n",
    "\n",
    "                    # Parcourir les uls\n",
    "                    uls = driver.find_elements(By.XPATH, ul_xpaths)\n",
    "                    action_aleatoire(driver)\n",
    "                    time.sleep(random.uniform(2, 5))\n",
    "                    # Parcourir chaque ul\n",
    "                    for ul_index, ul_element in enumerate(uls, start=1):\n",
    "                        try:\n",
    "                            # Trouver tous les li dans l'ul actuel\n",
    "                            li_elements = ul_element.find_elements(By.XPATH, \"./li\")\n",
    "\n",
    "                            # Parcourir chaque li\n",
    "                            \n",
    "                            for li_index, li_element in enumerate(li_elements, start=1):\n",
    "                                # Obtenir tous les éléments h3 et div à l'intérieur du li\n",
    "                                h3_elements = li_element.find_elements(By.XPATH, \"./h3\")\n",
    "                                div_elements = li_element.find_elements(By.XPATH, \"./div\")\n",
    "\n",
    "                                # Concaténer les textcontents de tous les h3 et div\n",
    "                                li_textcontent = \" \".join(element.get_attribute('textContent') for element in h3_elements + div_elements)\n",
    "\n",
    "                                # Ajouter le résultat au dictionnaire\n",
    "                                results[f\"ul{ul_index}_li{li_index}\"] = f\",{li_textcontent}\"\n",
    "\n",
    "                        except NoSuchElementException:\n",
    "                            print(\"UL non trouvé\")\n",
    "\n",
    "                    # Afficher les résultats\n",
    "                    #for key, value in results.items():\n",
    "                        #print(f\"{key}: {value}\")\n",
    "                    data.append(tuple(results.values()))\n",
    "                    data_final.append(data)\n",
    "                    time.sleep(random.uniform(2, 3))\n",
    "                    #print(data_final)\n",
    "                    print(\"+1\")\n",
    "                    csv_file_path = \"data.csv\"\n",
    "                    csv_columns = [\n",
    "                        \"Nom du véhicule\",\n",
    "                        \"Caractéristiques\",\n",
    "                        \"Prix\",\n",
    "                        \"Durée de publication\",\n",
    "                        \"Volume du coffre\",\n",
    "                        \"Points forts\",\n",
    "                        \"Équipements\"\n",
    "                    ]\n",
    "\n",
    "\n",
    "                    with open('thread2.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                        csv_writer = csv.writer(csvfile)\n",
    "                        csv_writer.writerow(data)       \n",
    "\n",
    "\n",
    "\n",
    "                except StaleElementReferenceException:\n",
    "                    # Si l'élément de lien est obsolète, afficher un message\n",
    "                    print(\"StaleElementReferenceException pour le lien :\", link.get_attribute(\"href\"))\n",
    "\n",
    "                except StaleElementReferenceException:\n",
    "                    # Si l'élément de lien est obsolète, afficher un message\n",
    "                    print(\"StaleElementReferenceException pour le lien :\", link)\n",
    "                    pass\n",
    "                except TimeoutException as e:\n",
    "                    print(f\"TimeoutException: {e}\")\n",
    "                    pass\n",
    "                    # Handle the timeout exception\n",
    "                except WebDriverException as e:\n",
    "                    print(f\"WebDriverException: {e}\")\n",
    "                    pass\n",
    "        except StaleElementReferenceException:\n",
    "            # If the element is stale, refind the links and continue\n",
    "            print(\"StaleElementReferenceException. Refinding links.\")\n",
    "            links = driver.find_elements(By.XPATH, xpath_expression)\n",
    "            continue\n",
    "        except NoSuchElementException:\n",
    "            # Si l'élément n'est pas trouvé, cela signifie probablement que la page n'existe pas\n",
    "            print(\"Fin de la boucle : La page\", current_page, \"n'existe pas.\")\n",
    "            pass\n",
    "        # Passer à la page suivante\n",
    "        current_page += 1\n",
    "        \n",
    "\n",
    "    # Fermer le navigateur à la fin\n",
    "    driver.quit()\n",
    "\n",
    "# Number of threads\n",
    "num_threads = 4\n",
    "\n",
    "# Create a list to store WebDriver instances\n",
    "drivers = [initialize_driver() for _ in range(num_threads)]\n",
    "\n",
    "# Define the range of pages you want to scrape\n",
    "start_page = 0\n",
    "end_page = 500\n",
    "# Calculate the step size to distribute pages evenly\n",
    "step = (end_page - start_page) // num_threads\n",
    "# Create a list to store thread links\n",
    "thread_links = [[] for _ in range(num_threads)]\n",
    "# Use ThreadPoolExecutor to run tasks concurrently\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit tasks to the pool for the specified range of pages\n",
    "    futures = [executor.submit(scrape_page, base_url, page, step, driver, thread_links[i]) for i, (page, driver) in enumerate(zip(range(start_page, end_page, step), drivers))]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "\n",
    "# Close the WebDriver instances\n",
    "for driver in drivers:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
