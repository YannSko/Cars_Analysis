{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7150d4-b456-4b66-8d97-282afa699429",
   "metadata": {},
   "source": [
    "# Scrape India\n",
    "\n",
    "Get the site : https://www.carwale.com/used/cars-for-sale/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1cca0f-1205-456a-bb98-f404d1a515cc",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35edb4d4-10af-4447-b080-7cb546f494c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.webdriver.common.service import Service\n",
    "from selenium.webdriver.common.service import Service\n",
    "from fake_useragent import UserAgent\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import random\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a482a-7423-46dc-8395-beab0772b698",
   "metadata": {},
   "source": [
    "## Fonctions Annexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b991270-d406-49d5-9289-4d3b45374bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_button(driver, xpath):\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH, xpath)\n",
    "        button.click()\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Le bouton avec l'xpath '{xpath}' est introuvable.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efcbf0b-b69f-4c3f-ab31-db831ea6686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_content(driver, xpath, content_type='text', max_retries=3, timeout=8):\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            # Trouver tous les éléments correspondant à l'XPath fourni\n",
    "            elements = WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "            )\n",
    "\n",
    "            # Extraire le contenu spécifié pour chaque élément\n",
    "            if content_type == 'text':\n",
    "                result = [element.text for element in elements]\n",
    "            elif content_type == 'href':\n",
    "                result = [element.get_attribute('href') for element in elements]\n",
    "            else:\n",
    "                raise ValueError(\"Type de contenu non pris en charge. Utilisez 'text' ou 'href'.\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout de {timeout} secondes atteint. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Élément non trouvé. Vérifiez votre XPath. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except StaleElementReferenceException:\n",
    "            print(f\"Stale Element Reference Exception. L'élément n'est plus attaché au DOM. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Une erreur s'est produite : {str(e)}\")\n",
    "\n",
    "    print(f\"Impossible de trouver et extraire le contenu après {max_retries} tentatives.\")\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8d06a9-7a26-4cea-bc62-633a64e27b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_aleatoire(driver):\n",
    "    actions_possibles = [\"scroll_full\", \"scroll_half\", \"move_to_element\"]\n",
    "    action_choisie = random.choice(actions_possibles)\n",
    "\n",
    "    # Enregistrer la position actuelle de la page\n",
    "    current_scroll_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "\n",
    "    if action_choisie == \"scroll_full\":\n",
    "        # Action aléatoire : Faites défiler la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    elif action_choisie == \"scroll_half\":\n",
    "        # Action aléatoire : Faites défiler la moitié de la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight / 2);\")\n",
    "    elif action_choisie == \"move_to_element\":\n",
    "        # Action aléatoire : Bougez la souris vers un élément aléatoire (par exemple, div de class PriceInformation_classifiedPrice__b-Jae)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element_to_move = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'center')))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", element_to_move)\n",
    "\n",
    "    # Revenir à la position enregistrée\n",
    "    driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ee7a3f-c60e-4814-99a6-3f09489764bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    ua = UserAgent()\n",
    "    user_agent = ua.random\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccb79e-9ec9-4294-be52-bf4dc39c0bad",
   "metadata": {},
   "source": [
    "## lien_ xpath utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba7d57a-7115-49b5-a721-bba92f6d60ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nV1\\n    \\nPrix moyen marché : dans la div de class o-YCHtV o-fHmpzP o-AxjCR o-bIMsfE o-fhuTtI\\nle p de class o-bkmzIL o-eZTujG o-eqqVmt o-bdcqQE\\nprix neuf : \\n    div de class o-YCHtV o-fHmpzP o-AxjCR  \\n    le p de class o-bkmzIL o-eZTujG o-eqqVmt o-bdcqQE\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "V1\n",
    "    \n",
    "Prix moyen marché : dans la div de class o-YCHtV o-fHmpzP o-AxjCR o-bIMsfE o-fhuTtI\n",
    "le p de class o-bkmzIL o-eZTujG o-eqqVmt o-bdcqQE\n",
    "prix neuf : \n",
    "    div de class o-YCHtV o-fHmpzP o-AxjCR  \n",
    "    le p de class o-bkmzIL o-eZTujG o-eqqVmt o-bdcqQE\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49d13b-3164-4703-8d8b-46d10d37aa73",
   "metadata": {},
   "source": [
    "# Initialize the driver\n",
    "driver = initialize_driver()\n",
    "\n",
    "# Load the page\n",
    "driver.get(\"https://www.carwale.com/used/cars-for-sale/\")\n",
    "\n",
    "#  popup\n",
    "popup_button_xpath = \".//span[contains(@class, 'o-frwuxB o-brXWGL o-cjsCNH o-dAFptd o-cDoIpQ o-cpnuEd o-dsiSgT o-NBTwp o-fuiuOo o-eoatGj dbDC7C o-eNbQSA o-brXWGL o-fzoTtm o-fmSMPH o-fznJFh o-fzptUA o-emXQxE o-fzptYC o-evuuYC ')]\"\n",
    "\n",
    "# Check popupis present \n",
    "try:\n",
    "    popup_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, popup_button_xpath))\n",
    "    )\n",
    "\n",
    "    # Click \n",
    "    popup_button.click()\n",
    "\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Define the XPath for the elements\n",
    "xpath = \".//div[@class='o-fznJzu o-fznJPk o-fzptZB o-fzptOP']//a \"\n",
    "\n",
    "try:\n",
    "    # Wait for the elements to be present\n",
    "    elements_present = EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "    WebDriverWait(driver, 5).until(elements_present)\n",
    "\n",
    "    # Call the scrape_content function to retrieve hrefs\n",
    "    all_pages_href = scrape_content(driver, xpath, content_type='href')\n",
    "    print(all_pages_href)\n",
    "    try:\n",
    "        for car_page in all_pages_href:\n",
    "            # Open the link\n",
    "            driver.get(car_page)\n",
    "            print(car_page)\n",
    "            # XPath for Marque + modele\n",
    "            marque_modele_xpath = \".//h1[@class='o-dAvrcB o-eZTujG o-eqqVmt']\"\n",
    "            marque_modele = scrape_content(driver, marque_modele_xpath, content_type='text')\n",
    "            print(marque_modele)\n",
    "            # XPath for prix\n",
    "            prix_xpath = \".//div[@class='o-cpnuEd o-dGBYL o-SoIQT o-Hyyko o-fzpilz o-fznJzb o-lIIwF o-fzptOP']//span[@class='o-eZTujG o-eqqVmt o-cscLpt']\"\n",
    "            prix = scrape_content(driver, prix_xpath, content_type='text')\n",
    "            carac_xpath = \".//div[@class='lwnY3h l9NkHx o-YCHtV o-djSZRV o-cDkpxz o-bIMsfE o-dgboEW o-eZrAYv o-fbEicu o-bCRRBE']\"\n",
    "            carac_content = scrape_content(driver, carac_xpath, content_type='text')\n",
    "            print(\"carc:\", carac_content)\n",
    "            print(prix)\n",
    "            \n",
    "            # spef\n",
    "            \n",
    "            span_spef_xpath = \".//div[contains(@class, 'o-brXWGL o-bqHweY o-OisZk o-frwuxB ME7bfG   o-bfyaNx')]//span[1]\"\n",
    "            click_success_spef = click_button(driver, span_spef_xpath)\n",
    "\n",
    "            if click_success_spef:\n",
    "                # Scroll jusqu'en bas de la page pour garantir que toutes les divs sont chargées\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "\n",
    "                # Cliquer sur toutes les divs pour afficher le contenu\n",
    "                divs_spef_xpath = \".//div[contains(@class, 'o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                #divs_spef_xpath = \".//div[contains(@class, 'o-cpnuEd o-frwuxB o-OisZk o-dsiSgT o-fzptZB o-fbZjxZ o-fzptOP o-fraaKH o-fzptVd o-fzptYr')]\"\n",
    "                divs_spef = driver.find_elements(By.XPATH, divs_spef_xpath)\n",
    "\n",
    "                print(\"Nombre de divs_spef :\", len(divs_spef))\n",
    "\n",
    "                for div_spef in divs_spef:\n",
    "                    try:\n",
    "                        # Scroller chaque div dans la vue\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_spef)\n",
    "                        time.sleep(1)  # Ajouter une pause si nécessaire\n",
    "                        div_spef.click()\n",
    "                        time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "                    except:\n",
    "                        # Ignorer les erreurs liées aux clics impossibles\n",
    "                        pass\n",
    "\n",
    "                # Récupérer le texte des li pour spef\n",
    "                time.sleep(5)\n",
    "                spef_ul_xpath = \".//ul[contains(@class, 'o-cpnuEd o-XylGE o-eNbQSA o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                spef_li_content = scrape_content(driver, spef_ul_xpath, content_type='text')\n",
    "\n",
    "                # Utilisez spef_li_content pour les données récupérées\n",
    "                print(\"Contenu pour spef :\", spef_li_content)\n",
    "            else:\n",
    "                print(\"Erreur lors du clic sur spef.\")\n",
    "\n",
    "            # features\n",
    "            \n",
    "            # Click on the element with data-index=\"1\"\n",
    "            element_with_data_index_xpath = \"./html/body/div[1]/div[2]/div[2]/div[1]/div/div[4]/div/div/div/div[1]/div/ul/li[2]/div/span\"\n",
    "            click_success_element_with_data_index = click_button(driver, element_with_data_index_xpath)\n",
    "\n",
    "            if click_success_element_with_data_index:\n",
    "                # Wait for some time to ensure the content is loaded after clicking\n",
    "                time.sleep(2)\n",
    "\n",
    "                # Now, you can perform actions on the element after clicking\n",
    "                # Scroll jusqu'en bas de la page pour garantir que toutes les divs sont chargées\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "\n",
    "                # Cliquer sur toutes les divs pour afficher le contenu\n",
    "                divs_features_xpath = \".//div[contains(@class, 'o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "\n",
    "                # divs_features_xpath = \".//div[contains(@class, 'o-cpnuEd o-frwuxB o-OisZk o-dsiSgT o-fzptZB o-fbZjxZ o-fzptOP o-fraaKH o-fzptVd o-fzptYr')]\"\n",
    "                divs_features = driver.find_elements(By.XPATH, divs_features_xpath)\n",
    "\n",
    "                print(\"Nombre de divs_features :\", len(divs_features))\n",
    "\n",
    "                for div_features in divs_features:\n",
    "                    try:\n",
    "                        # Scroller chaque div dans la vue\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_features)\n",
    "                       \n",
    "                        div_to_open_xpath = \".//div[contains(@class, 'o-cpnuEd o-frwuxB o-OisZk o-dsiSgT o-fzptZB o-fbZjxZ o-fzptOP o-fraaKH o-fzptVd o-fzptYr')]\"\n",
    "                        divs_to_open = driver.find_elements(By.XPATH,  div_to_open_xpath)\n",
    "                       \n",
    "\n",
    "                        # Wait for the element to become clickable\n",
    "                        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH,  div_to_open_xpath)))\n",
    "\n",
    "                        divs_to_open.click()\n",
    "                        time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "                    except Exception as e:\n",
    "                        # Ignorer les erreurs liées aux clics impossibles\n",
    "                        print(f\"Erreur lors du clic sur une div : {str(e)}\")\n",
    "                        pass\n",
    "\n",
    "                # Récupérer le texte des li pour features\n",
    "                features_ul_xpath = \".//ul[contains(@class, 'arv_ME o-cpnuEd o-XylGE o-eNbQSA o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                features_li_content = scrape_content(driver, features_ul_xpath, content_type='text')\n",
    "\n",
    "                # Utilisez features_li_content pour les données récupérées\n",
    "                print(\"Contenu pour features :\", features_li_content)\n",
    "            else:\n",
    "                print(f\"Erreur lors du clic sur l'élément avec data-index='1'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver when done\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59d06c-f313-4bab-9bdb-27712ce87d06",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e758d63-58d0-4e4b-9d19-fc528990d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the driver\n",
    "driver = initialize_driver()\n",
    "\n",
    "# Load the page\n",
    "driver.get(\"https://www.carwale.com/used/cars-for-sale/\")\n",
    "\n",
    "#  popup\n",
    "popup_button_xpath = \".//span[contains(@class, 'o-frwuxB o-brXWGL o-cjsCNH o-dAFptd o-cDoIpQ o-cpnuEd o-dsiSgT o-NBTwp o-fuiuOo o-eoatGj dbDC7C o-eNbQSA o-brXWGL o-fzoTtm o-fmSMPH o-fznJFh o-fzptUA o-emXQxE o-fzptYC o-evuuYC ')]\"\n",
    "\n",
    "# Check popupis present \n",
    "try:\n",
    "    popup_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, popup_button_xpath))\n",
    "    )\n",
    "\n",
    "    # Click \n",
    "    popup_button.click()\n",
    "\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Define the XPath for the elements\n",
    "xpath = \".//div[@class='o-fznJzu o-fznJPk o-fzptZB o-fzptOP']//a \"\n",
    "\n",
    "try:\n",
    "    # Wait for the elements to be present\n",
    "    elements_present = EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "    WebDriverWait(driver, 5).until(elements_present)\n",
    "\n",
    "    # Call the scrape_content function to retrieve hrefs\n",
    "    all_pages_href = scrape_content(driver, xpath, content_type='href')\n",
    "    print(all_pages_href)\n",
    "    try:\n",
    "        for car_page in all_pages_href:\n",
    "            # Open the link\n",
    "            driver.get(car_page)\n",
    "            print(car_page)\n",
    "            # XPath for Marque + modele\n",
    "            marque_modele_xpath = \".//h1[@class='o-dAvrcB o-eZTujG o-eqqVmt']\"\n",
    "            marque_modele = scrape_content(driver, marque_modele_xpath, content_type='text')\n",
    "            print(marque_modele)\n",
    "            # XPath for prix\n",
    "            prix_xpath = \".//div[@class='o-cpnuEd o-dGBYL o-SoIQT o-Hyyko o-fzpilz o-fznJzb o-lIIwF o-fzptOP']//span[@class='o-eZTujG o-eqqVmt o-cscLpt']\"\n",
    "            prix = scrape_content(driver, prix_xpath, content_type='text')\n",
    "            carac_xpath = \".//div[@class='lwnY3h l9NkHx o-YCHtV o-djSZRV o-cDkpxz o-bIMsfE o-dgboEW o-eZrAYv o-fbEicu o-bCRRBE']\"\n",
    "            carac_content = scrape_content(driver, carac_xpath, content_type='text')\n",
    "            print(\"carc:\", carac_content)\n",
    "            print(prix)\n",
    "            \n",
    "            # spef\n",
    "            #\n",
    "            span_spef_xpath = \"./html/body/div[1]/div[2]/div[2]/div[1]/div/div[4]/div/div/div/div[1]/div/ul/li[1]/div/span\"\n",
    "            click_success_spef = click_button(driver, span_spef_xpath)\n",
    "\n",
    "            if click_success_spef:\n",
    "                # Wait for the content to load after clicking\n",
    "                time.sleep(2)\n",
    "\n",
    "                # Scroll jusqu'en bas de la page pour garantir que toutes les divs sont chargées\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "\n",
    "                # Cliquer sur toutes les divs pour afficher le contenu\n",
    "                divs_spef_xpath = \".//div[contains(@class, 'o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                divs_spef = driver.find_elements(By.XPATH, divs_spef_xpath)\n",
    "\n",
    "                print(\"Nombre de divs_spef :\", len(divs_spef))\n",
    "\n",
    "                # Initialize an empty set to store unique specifications\n",
    "                unique_specifications = set()\n",
    "                for div_spef in divs_spef:\n",
    "                    try:\n",
    "                        # Scroller chaque div dans la vue\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_spef)\n",
    "\n",
    "                        # Click on the div using JavaScript\n",
    "                        driver.execute_script(\"arguments[0].click();\", div_spef)\n",
    "\n",
    "                        # Wait for the content to load after clicking\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        # Récupérer le texte des li pour spef\n",
    "                        spef_ul_xpath = \".//ul[contains(@class, 'o-cpnuEd o-XylGE o-eNbQSA o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                        spef_li_content = scrape_content(driver, spef_ul_xpath, content_type='text')\n",
    "\n",
    "                        # Convert the list to a tuple before adding to the set\n",
    "                        spefs_tuple = tuple(spef_li_content)\n",
    "                        unique_specifications.add(spefs_tuple)\n",
    "                    except Exception as e:\n",
    "                        # Ignorer les erreurs liées aux clics impossibles\n",
    "                        print(f\"Erreur lors du clic sur une div : {str(e)}\")\n",
    "                        pass\n",
    "\n",
    "                # Convert the set of tuples to a list if needed\n",
    "                unique_specifications_list = [list(item) for item in unique_specifications]\n",
    "\n",
    "                # Print the list containing unique specifications\n",
    "                print(\"Contenu pour les specifications uniques :\", unique_specifications_list)\n",
    "            else:\n",
    "                print(\"Erreur lors du clic sur spef.\")\n",
    "\n",
    "                '''\n",
    "                for div_spef in divs_spef:\n",
    "                    try:\n",
    "                        # Scroller chaque div dans la vue\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_spef)\n",
    "                        time.sleep(1)  # Ajouter une pause si nécessaire\n",
    "                        div_spef.click()\n",
    "                        time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "                    except:\n",
    "                        # Ignorer les erreurs liées aux clics impossibles\n",
    "                        pass\n",
    "\n",
    "                # Récupérer le texte des li pour spef\n",
    "                time.sleep(5)\n",
    "                spef_ul_xpath = \".//ul[contains(@class, 'o-cpnuEd o-XylGE o-eNbQSA o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                spef_li_content = scrape_content(driver, spef_ul_xpath, content_type='text')\n",
    "\n",
    "                # Utilisez spef_li_content pour les données récupérées\n",
    "                print(\"Contenu pour spef :\", spef_li_content)\n",
    "            else:\n",
    "                print(\"Erreur lors du clic sur spef.\")\n",
    "                '''\n",
    "            # features\n",
    "            \n",
    "            # Click on the element with data-index=\"1\"\n",
    "            element_with_data_index_xpath = \"./html/body/div[1]/div[2]/div[2]/div[1]/div/div[4]/div/div/div/div[1]/div/ul/li[2]/div/span\"\n",
    "            click_success_element_with_data_index = click_button(driver, element_with_data_index_xpath)\n",
    "\n",
    "            if click_success_element_with_data_index:\n",
    "                # Wait for some time to ensure the content is loaded after clicking\n",
    "                time.sleep(2)\n",
    "\n",
    "                # Now, you can perform actions on the element after clicking\n",
    "                # Scroll jusqu'en bas de la page pour garantir que toutes les divs sont chargées\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "\n",
    "                # Cliquer sur toutes les divs pour afficher le contenu\n",
    "               \n",
    "                div_to_open_xpath = \".//div[contains(@class, 'o-cpnuEd o-frwuxB o-OisZk o-dsiSgT o-fzptZB o-fbZjxZ o-fzptOP o-fraaKH o-fzptVd o-fzptYr')]\"\n",
    "                divs_to_open = driver.find_elements(By.XPATH, div_to_open_xpath)\n",
    "\n",
    "                print(\"Nombre de divs_to_open :\", len(divs_to_open))\n",
    "\n",
    "                # Initialize an empty set to store unique features\n",
    "                unique_features = set()\n",
    "\n",
    "                for div_to_open in divs_to_open:\n",
    "                    try:\n",
    "                        # Scroller chaque div dans la vue\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", div_to_open)\n",
    "\n",
    "                        # Click on the div using JavaScript\n",
    "                        driver.execute_script(\"arguments[0].click();\", div_to_open)\n",
    "                        time.sleep(2)  # Ajouter une pause si nécessaire\n",
    "\n",
    "                        # Récupérer le texte des li pour features\n",
    "                        features_ul_xpath = \".//ul[contains(@class, 'arv_ME o-cpnuEd o-XylGE o-eNbQSA o-bIMsfE o-djSZRV o-GFmfi')]\"\n",
    "                        features_li_content = scrape_content(driver, features_ul_xpath, content_type='text')\n",
    "\n",
    "                        # Convert the list to a tuple before adding to the set\n",
    "                        features_tuple = tuple(features_li_content)\n",
    "                        unique_features.add(features_tuple)\n",
    "                    except Exception as e:\n",
    "                        # Ignorer les erreurs liées aux clics impossibles\n",
    "                        print(f\"Erreur lors du clic sur une div : {str(e)}\")\n",
    "                        pass\n",
    "\n",
    "                # Convert the set of tuples to a list if needed\n",
    "                unique_features_list = [list(item) for item in unique_features]\n",
    "\n",
    "                # Print the list containing unique features\n",
    "                print(\"Contenu pour les features uniques :\", unique_features_list)\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver when done\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663b57b-ec11-4314-af63-30fad02e1724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
