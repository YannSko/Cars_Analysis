{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop de requêtes, en pause pendant un moment...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Cars_Analysis\\World_Cars\\America\\Russie\\script\\scrape_data.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m page_number \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, total_pages \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     main_page_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.avito.ru/all/avtomobili\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     car_links \u001b[39m=\u001b[39m get_car_links(main_page_url, page_number)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39mfor\u001b[39;00m car_link \u001b[39min\u001b[39;00m car_links:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mScraping details for car: \u001b[39m\u001b[39m{\u001b[39;00mcar_link\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\Cars_Analysis\\World_Cars\\America\\Russie\\script\\scrape_data.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrop de requêtes, en pause pendant un moment...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)  \u001b[39m# Pause de 10 secondes en cas d'erreur 429\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m get_car_links(main_url, page_number)  \u001b[39m# Réessayer après la pause\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m soup \u001b[39m=\u001b[39m bs(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32md:\\Cars_Analysis\\World_Cars\\America\\Russie\\script\\scrape_data.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmain_url\u001b[39m}\u001b[39;00m\u001b[39m?p=\u001b[39m\u001b[39m{\u001b[39;00mpage_number\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUser-agent\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mMozilla/5.0\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m429\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Cars_Analysis/World_Cars/America/Russie/script/scrape_data.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrop de requêtes, en pause pendant un moment...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1056\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1057\u001b[0m         (\n\u001b[0;32m   1058\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1064\u001b[0m     )\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    411\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs\n\u001b[0;32m    412\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(context, \u001b[39m\"\u001b[39m\u001b[39mload_default_certs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    436\u001b[0m     default_ssl_context\n\u001b[0;32m    437\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    439\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock\u001b[39m.\u001b[39mversion() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mTLSv1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTLSv1.1\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    440\u001b[0m ):\n",
      "File \u001b[1;32md:\\ANACONDA\\Lib\\site-packages\\urllib3\\util\\ssl_.py:402\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39mif\u001b[39;00m ca_certs \u001b[39mor\u001b[39;00m ca_cert_dir \u001b[39mor\u001b[39;00m ca_cert_data:\n\u001b[0;32m    401\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m         context\u001b[39m.\u001b[39mload_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\n\u001b[0;32m    403\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    404\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import csv\n",
    "from urllib.parse import urljoin\n",
    " \n",
    "def get_car_links(main_url, page_number):\n",
    "    try:\n",
    "        url = f\"{main_url}?p={page_number}\"\n",
    "        response = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            print(f\"Trop de requêtes, en pause pendant un moment...\")\n",
    "            time.sleep(2)  # Pause de 10 secondes en cas d'erreur 429\n",
    "            return get_car_links(main_url, page_number)  # Réessayer après la pause\n",
    "        \n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        base_url = \"https://www.avito.ru/all/avtomobili\"  # Ajoutez le domaine de base ici\n",
    "        car_links = [urljoin(base_url, a['href']) for a in soup.select('a.styles-module-root-QmppR styles-module-root_noVisited-aFA10')]\n",
    "        return car_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des liens de la page {page_number} : {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_car_details(car_url):\n",
    "    try:\n",
    "        response = requests.get(car_url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        car_soup = bs(response.text, 'html.parser')\n",
    "\n",
    "        # Obtenez le nom de la voiture\n",
    "        car_name_element = car_soup.select_one('.styles-module-root-TWVKW.styles-module-root-_KFFt.styles-module-size_xxxl-A2qfi.styles-module-size_xxxl-_bK04.stylesMarningNormal-module-root-OSCNq.stylesMarningNormal-module-header-3xl-k0ckc')\n",
    "        car_name = car_name_element.get_text(strip=True) if car_name_element else \"Nom non trouvé\"\n",
    "\n",
    "        # Obtenez les détails de la voiture\n",
    "        car_details_elements = car_soup.select('.item-view .item-params')  # Mise à jour du sélecteur\n",
    "        car_features = {}\n",
    "\n",
    "        for detail_element in car_details_elements:\n",
    "            feature_icon = detail_element.select_one('.icones')\n",
    "            feature_name = detail_element.select_one('p').get_text(strip=True) if detail_element.select_one('p') else \"Nom de la caractéristique non trouvé\"\n",
    "\n",
    "            if feature_icon:\n",
    "                feature_class = feature_icon.get('class')[1]\n",
    "                car_features[feature_class] = feature_name\n",
    "\n",
    "        # Ajoutez du code pour extraire le prix de la voiture\n",
    "        car_price_element = car_soup.select_one('.styles-module-size_xxxl-A2qfi')\n",
    "        car_price = car_price_element.get_text(strip=True) if car_price_element else \"Prix non trouvé\"\n",
    "\n",
    "        print(f\"Nom de la voiture: {car_name}\")\n",
    "        print(f\"Caractéristiques de la voiture:\\n{car_features}\")\n",
    "        print(f\"Prix de la voiture: {car_price}\\n{'='*30}\")\n",
    "\n",
    "        return {'Car Name': car_name, 'Car Features': car_features, 'Car Price': car_price}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des détails de la voiture : {e}\")\n",
    "        return None\n",
    "\n",
    "total_pages = 2  # Modifier le nombre total de pages selon les besoins\n",
    "car_details_list = []\n",
    "\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    main_page_url = 'https://www.avito.ru/all/avtomobili'\n",
    "    car_links = get_car_links(main_page_url, page_number)\n",
    "\n",
    "    for car_link in car_links:\n",
    "        print(f\"Scraping details for car: {car_link}\")\n",
    "        car_detail = scrape_car_details(car_link)\n",
    "        \n",
    "        if car_detail:\n",
    "            car_details_list.append(car_detail)\n",
    "        else:\n",
    "            print(f\"Aucun détail trouvé pour la voiture : {car_link}\")\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "# Ajout de débogage\n",
    "print(\"Nombre total de détails récupérés :\", len(car_details_list))\n",
    "\n",
    "# Écrire les détails des voitures dans un fichier CSV\n",
    "with open('car_details_avito.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Car Name', 'Car Features', 'Car Price']  # Ajoutez 'Car Price' à la liste\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "    \n",
    "    for detail in car_details_list:\n",
    "        csv_writer.writerow(detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de la récupération des liens de la page 1 : 429 Client Error: Too Many Requests for url: https://www.avito.ru/all/avtomobili?p=1\n",
      "Nombre total de détails récupérés : 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def get_car_links(main_url, page_number):\n",
    "    try:\n",
    "        url = f\"{main_url}?p={page_number}\"\n",
    "        response = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        car_links = [a['href'] for a in soup.select('a._blank')]\n",
    "        return car_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des liens de la page {page_number} : {e}\")\n",
    "        return []\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_car_details(url):\n",
    "    try:\n",
    "        # Faites une demande HTTP à l'URL de la voiture\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Analysez la page avec BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Obtenez le nom du véhicule\n",
    "        name_element = soup.select_one('.block-title-list h2 a span.title-block.brand')\n",
    "        car_name = name_element.text.strip() if name_element else \"Nom non trouvé\"\n",
    "\n",
    "        # Obtenez le prix du véhicule\n",
    "        price_element = soup.select_one('.prix')\n",
    "        car_price = price_element.text.strip() if price_element else \"Prix non trouvé\"\n",
    "\n",
    "        # Affichez les détails récupérés\n",
    "        print(f\"Nom du véhicule: {car_name}\")\n",
    "        print(f\"Prix du véhicule: {car_price}\")\n",
    "        print('=' * 30)\n",
    "\n",
    "        return {\n",
    "            'Car Name': car_name,\n",
    "            'Car Price': car_price\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des détails du véhicule : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def scrap_pages(main_url, start_page, end_page):\n",
    "    car_details_list = []\n",
    "\n",
    "    for page_number in range(start_page, end_page + 1):\n",
    "        car_links = get_car_links(main_url, page_number)\n",
    "\n",
    "        for car_link in car_links:\n",
    "            print(f\"Scrapping details for car: {car_link}\")\n",
    "            car_detail = scrape_car_details(car_link)\n",
    "            \n",
    "            if car_detail:\n",
    "                car_details_list.append(car_detail)\n",
    "            else:\n",
    "                print(f\"Aucun détail trouvé pour la voiture : {car_link}\")\n",
    "            \n",
    "            time.sleep(2)  # Respectez les politiques du site pour éviter d'être bloqué\n",
    "\n",
    "    return car_details_list\n",
    "\n",
    "main_page_url = 'https://www.avito.ru/all/avtomobili'\n",
    "total_pages = 2  # Modifier le nombre total de pages selon les besoins\n",
    "start_page = 1\n",
    "end_page = total_pages\n",
    "car_details_list = scrap_pages(main_page_url, start_page, end_page)\n",
    "\n",
    "# Ajout de débogage\n",
    "print(\"Nombre total de détails récupérés :\", len(car_details_list))\n",
    "\n",
    "# Écrire les détails des voitures dans un fichier CSV\n",
    "with open('car_details_avito.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Car Name', 'Car Details', 'Car Price']  # Ajoutez 'Car Name' à la liste\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "    \n",
    "    for detail in car_details_list:\n",
    "        csv_writer.writerow(detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de détails récupérés : 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def get_car_links(main_url, page_number):\n",
    "    try:\n",
    "        url = f\"{main_url}?o={page_number}\"\n",
    "        response = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        car_links = [a['href'] for a in soup.select('a.tracker.LeadLink')]\n",
    "        return car_links\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des liens de la page {page_number} : {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_car_details(car_url):\n",
    "    try:\n",
    "        response = requests.get(car_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        car_soup = bs(response.text, 'html.parser')\n",
    "\n",
    "        # Ajoutez cette ligne pour imprimer le HTML de la page\n",
    "        print(car_soup.prettify())\n",
    "\n",
    "        # Reste du code pour extraire les détails de la voiture\n",
    "        brand = car_soup.select_one('.title-block.brand').text.strip()\n",
    "        model = car_soup.select_one('.title-block.sub-title').text.strip()\n",
    "        version = car_soup.select_one('.title-block.sub-title:nth-of-type(2)').text.strip()\n",
    "\n",
    "        old_price_element = car_soup.select_one('.old-prix s')\n",
    "        old_price = old_price_element.text.strip() if old_price_element else \"Prix initial non trouvé\"\n",
    "\n",
    "        current_price_element = car_soup.select_one('.prix')\n",
    "        current_price = current_price_element.text.strip() if current_price_element else \"Prix actuel non trouvé\"\n",
    "\n",
    "        credit_price_element = car_soup.select_one('.lead-credit-price .credit-prix')\n",
    "        credit_price = credit_price_element.text.strip() if credit_price_element else \"Détails de crédit non trouvés\"\n",
    "\n",
    "        print(f\"Marque: {brand}\")\n",
    "        print(f\"Modèle: {model}\")\n",
    "        print(f\"Version: {version}\")\n",
    "        print(f\"Prix initial: {old_price}\")\n",
    "        print(f\"Prix actuel: {current_price}\")\n",
    "        print(f\"Détails de crédit: {credit_price}\")\n",
    "        print('=' * 30)\n",
    "\n",
    "        return {\n",
    "            'Brand': brand,\n",
    "            'Model': model,\n",
    "            'Version': version,\n",
    "            'Old Price': old_price,\n",
    "            'Current Price': current_price,\n",
    "            'Credit Details': credit_price\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des détails de la voiture : {e}\")\n",
    "        return None\n",
    "\n",
    "main_page_url = 'https://www.leparking.fr/voiture-occasion/.html#!/voiture-occasion/%3Fid_pays%3D36'\n",
    "total_pages = 2  # Modifier le nombre total de pages selon les besoins\n",
    "car_details_list = []\n",
    "\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    car_links = get_car_links(main_page_url, page_number)\n",
    "\n",
    "    for car_link in car_links:\n",
    "        print(f\"Scrapping details for car: {car_link}\")\n",
    "        car_detail = scrape_car_details(car_link)\n",
    "        \n",
    "        if car_detail:\n",
    "            car_details_list.append(car_detail)\n",
    "        else:\n",
    "            print(f\"Aucun détail trouvé pour la voiture : {car_link}\")\n",
    "        \n",
    "        time.sleep(2)  # Respect the website's policies to avoid being blocked\n",
    "\n",
    "# Debugging information\n",
    "print(\"Nombre total de détails récupérés :\", len(car_details_list))\n",
    "\n",
    "# Write car details to a CSV file\n",
    "with open('car_details_ru.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Brand', 'Model', 'Version', 'Old Price', 'Current Price', 'Credit Details']\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "    \n",
    "    for detail in car_details_list:\n",
    "        csv_writer.writerow(detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 15 300 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 8 200 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 8 200 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 24 900 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 21 500 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 16 900 €\n",
      "==============================\n",
      "Nom du véhicule: Nom non trouvé\n",
      "Prix du véhicule: 29 500 €\n",
      "==============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation pour une page principale\u001b[39;00m\n\u001b[0;32m     77\u001b[0m main_page_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.leparking.fr/voiture-occasion/.html#!/voiture-occasion/\u001b[39m\u001b[38;5;132;01m%3F\u001b[39;00m\u001b[38;5;124mid_pays\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3D36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 78\u001b[0m all_car_details \u001b[38;5;241m=\u001b[39m scrape_all_cars(main_page_url)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Si des détails ont été récupérés avec succès, vous pouvez les utiliser comme bon vous semble\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_car_details:\n",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m, in \u001b[0;36mscrape_all_cars\u001b[1;34m(main_url)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m car_link \u001b[38;5;129;01min\u001b[39;00m car_links:\n\u001b[1;32m---> 37\u001b[0m     car_details \u001b[38;5;241m=\u001b[39m scrape_car_details(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.leparking.fr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcar_link\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m car_details:\n\u001b[0;32m     39\u001b[0m         all_car_details\u001b[38;5;241m.\u001b[39mappend(car_details)\n",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m, in \u001b[0;36mscrape_car_details\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_car_details\u001b[39m(url):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# Faites une demande HTTP à l'URL de la voiture\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m         response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     49\u001b[0m         response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# Analysez la page avec BeautifulSoup\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\33660\\anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_all_car_links(main_url):\n",
    "    try:\n",
    "        # Faites une demande HTTP à l'URL de la page principale\n",
    "        response = requests.get(main_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Analysez la page avec BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Obtenez tous les liens vers les voitures sur la page\n",
    "        car_links = [a['href'] for a in soup.select('.block-title-list a[href^=\"/voiture-occasion-detail/\"]')]\n",
    "\n",
    "        return car_links\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des liens de voitures : {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_cars(main_url):\n",
    "    all_car_details = []\n",
    "    current_page = 1\n",
    "\n",
    "    while True:\n",
    "        page_url = f\"{main_url}?o={current_page}\"\n",
    "        car_links = get_all_car_links(page_url)\n",
    "\n",
    "        if not car_links:\n",
    "            print(f\"Aucun lien de voiture trouvé sur la page {current_page}. Fin du scraping.\")\n",
    "            break\n",
    "\n",
    "        for car_link in car_links:\n",
    "            car_details = scrape_car_details(f\"https://www.leparking.fr{car_link}\")\n",
    "            if car_details:\n",
    "                all_car_details.append(car_details)\n",
    "\n",
    "        current_page += 1\n",
    "\n",
    "    return all_car_details\n",
    "\n",
    "def scrape_car_details(url):\n",
    "    try:\n",
    "        # Faites une demande HTTP à l'URL de la voiture\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Analysez la page avec BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Obtenez le nom du véhicule\n",
    "        name_element = soup.select_one('a.external.tag_f_titre')\n",
    "        car_name = name_element.find('span', class_='title-block brand three-dots').text.strip() if name_element else \"Nom non trouvé\"\n",
    "\n",
    "        # Obtenez le prix du véhicule\n",
    "        price_element = soup.select_one('.prix')\n",
    "        car_price = price_element.text.strip() if price_element else \"Prix non trouvé\"\n",
    "\n",
    "        # Affichez les détails récupérés\n",
    "        print(f\"Nom du véhicule: {car_name}\")\n",
    "        print(f\"Prix du véhicule: {car_price}\")\n",
    "        print('=' * 30)\n",
    "\n",
    "        return {\n",
    "            'Car Name': car_name,\n",
    "            'Car Price': car_price\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération des détails du véhicule : {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation pour une page principale\n",
    "main_page_url = 'https://www.leparking.fr/voiture-occasion/.html#!/voiture-occasion/%3Fid_pays%3D36'\n",
    "all_car_details = scrape_all_cars(main_page_url)\n",
    "\n",
    "# Si des détails ont été récupérés avec succès, vous pouvez les utiliser comme bon vous semble\n",
    "if all_car_details:\n",
    "    print(\"Détails de toutes les voitures récupérés avec succès:\")\n",
    "    print(all_car_details)\n",
    "else:\n",
    "    print(\"Aucun détail trouvé pour les voitures.\")\n",
    "\n",
    "def save_to_csv(car_details, filename='car_details.csv'):\n",
    "    fieldnames = ['Car Name', 'Car Price']\n",
    "\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write the data\n",
    "        for car in car_details:\n",
    "            writer.writerow(car)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
